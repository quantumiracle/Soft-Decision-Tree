compute003
5
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
{'input_dim': 8, 'output_dim': 4, 'depth': 5, 'lamda': -0.001, 'lr': 0.001, 'weight_decay': 0.0, 'batch_size': 1280, 'epochs': 40, 'cuda': True, 'log_interval': 100, 'exp_scheduler_gamma': 1.0, 'beta': True, 'greatest_path_probability': True, 'model_path': './model/trees/sdt_-0.001_id1'}
Epoch: 01 | Batch: 000 | CrossEntropy-loss: 1.38764 | Correct: 610/1280 | Difference: 0.9989358210859087
Epoch: 01 | Batch: 100 | CrossEntropy-loss: 1.27943 | Correct: 649/1280 | Difference: 0.9976536562346972
Epoch: 01 | Batch: 200 | CrossEntropy-loss: 1.18969 | Correct: 648/1280 | Difference: 0.9590948078243008
Epoch: 01 | Batch: 300 | CrossEntropy-loss: 1.09539 | Correct: 959/1280 | Difference: 0.9330507755373394
Epoch: 01 | Batch: 400 | CrossEntropy-loss: 0.99008 | Correct: 906/1280 | Difference: 0.923457652239901
Epoch: 01 | Batch: 500 | CrossEntropy-loss: 0.89123 | Correct: 919/1280 | Difference: 0.9138095647075131
Epoch: 01 | Batch: 600 | CrossEntropy-loss: 0.80074 | Correct: 919/1280 | Difference: 0.9112170052931546
Epoch: 01 | Batch: 700 | CrossEntropy-loss: 0.77299 | Correct: 922/1280 | Difference: 0.9075642031856795
Epoch: 01 | Batch: 800 | CrossEntropy-loss: 0.70038 | Correct: 968/1280 | Difference: 0.8998396807288151
Epoch: 01 | Batch: 900 | CrossEntropy-loss: 0.72391 | Correct: 936/1280 | Difference: 0.8875614746690588
Epoch: 01 | Batch: 1000 | CrossEntropy-loss: 0.68050 | Correct: 949/1280 | Difference: 0.8735364867312873
Epoch: 01 | Batch: 1100 | CrossEntropy-loss: 0.65138 | Correct: 955/1280 | Difference: 0.8599697168855196
Epoch: 01 | Batch: 1200 | CrossEntropy-loss: 0.67528 | Correct: 923/1280 | Difference: 0.8489038107518677
Epoch: 01 | Batch: 1300 | CrossEntropy-loss: 0.61512 | Correct: 963/1280 | Difference: 0.8414278832180574
Epoch: 01 | Batch: 1400 | CrossEntropy-loss: 0.65178 | Correct: 922/1280 | Difference: 0.8392413898137973
Epoch: 01 | Batch: 1500 | CrossEntropy-loss: 0.61790 | Correct: 947/1280 | Difference: 0.8398982139037636

Epoch: 01 | Testing Accuracy: 380277/504607 (75.361%) | Historical Best: 75.361% 

Epoch: 02 | Batch: 000 | CrossEntropy-loss: 0.58646 | Correct: 970/1280 | Difference: 0.8424262754713475
Epoch: 02 | Batch: 100 | CrossEntropy-loss: 0.60809 | Correct: 955/1280 | Difference: 0.8438218157868265
Epoch: 02 | Batch: 200 | CrossEntropy-loss: 0.57995 | Correct: 964/1280 | Difference: 0.8465016796387006
Epoch: 02 | Batch: 300 | CrossEntropy-loss: 0.52991 | Correct: 990/1280 | Difference: 0.8493822022725654
Epoch: 02 | Batch: 400 | CrossEntropy-loss: 0.53915 | Correct: 987/1280 | Difference: 0.8517263974560778
Epoch: 02 | Batch: 500 | CrossEntropy-loss: 0.52644 | Correct: 997/1280 | Difference: 0.8526285376871078
Epoch: 02 | Batch: 600 | CrossEntropy-loss: 0.52143 | Correct: 1012/1280 | Difference: 0.8523828646797943
Epoch: 02 | Batch: 700 | CrossEntropy-loss: 0.50016 | Correct: 1013/1280 | Difference: 0.8533683895480221
Epoch: 02 | Batch: 800 | CrossEntropy-loss: 0.52918 | Correct: 989/1280 | Difference: 0.8548310395293277
Epoch: 02 | Batch: 900 | CrossEntropy-loss: 0.47370 | Correct: 1030/1280 | Difference: 0.8555692510859436
Epoch: 02 | Batch: 1000 | CrossEntropy-loss: 0.48243 | Correct: 1036/1280 | Difference: 0.8558960457431711
Epoch: 02 | Batch: 1100 | CrossEntropy-loss: 0.48295 | Correct: 1008/1280 | Difference: 0.8551637217907253
Epoch: 02 | Batch: 1200 | CrossEntropy-loss: 0.48314 | Correct: 1006/1280 | Difference: 0.8552619010980352
Epoch: 02 | Batch: 1300 | CrossEntropy-loss: 0.45082 | Correct: 1068/1280 | Difference: 0.8546369416654499
Epoch: 02 | Batch: 1400 | CrossEntropy-loss: 0.45062 | Correct: 1063/1280 | Difference: 0.8525732179001722
Epoch: 02 | Batch: 1500 | CrossEntropy-loss: 0.46677 | Correct: 1052/1280 | Difference: 0.8519760438786333

Epoch: 02 | Testing Accuracy: 415556/504607 (82.352%) | Historical Best: 82.352% 

Epoch: 03 | Batch: 000 | CrossEntropy-loss: 0.46328 | Correct: 1057/1280 | Difference: 0.851309621196494
Epoch: 03 | Batch: 100 | CrossEntropy-loss: 0.43949 | Correct: 1073/1280 | Difference: 0.8508642399001844
Epoch: 03 | Batch: 200 | CrossEntropy-loss: 0.44658 | Correct: 1055/1280 | Difference: 0.8502025736192922
Epoch: 03 | Batch: 300 | CrossEntropy-loss: 0.43944 | Correct: 1072/1280 | Difference: 0.8504632079486072
Epoch: 03 | Batch: 400 | CrossEntropy-loss: 0.42246 | Correct: 1063/1280 | Difference: 0.8516488790838853
Epoch: 03 | Batch: 500 | CrossEntropy-loss: 0.44237 | Correct: 1052/1280 | Difference: 0.8525414568800233
Epoch: 03 | Batch: 600 | CrossEntropy-loss: 0.41775 | Correct: 1085/1280 | Difference: 0.8530928924691044
Epoch: 03 | Batch: 700 | CrossEntropy-loss: 0.42092 | Correct: 1066/1280 | Difference: 0.8533962176872797
Epoch: 03 | Batch: 800 | CrossEntropy-loss: 0.42642 | Correct: 1045/1280 | Difference: 0.854083333498963
Epoch: 03 | Batch: 900 | CrossEntropy-loss: 0.41169 | Correct: 1067/1280 | Difference: 0.8549434256014504
Epoch: 03 | Batch: 1000 | CrossEntropy-loss: 0.40073 | Correct: 1071/1280 | Difference: 0.8556450556619015
Epoch: 03 | Batch: 1100 | CrossEntropy-loss: 0.43765 | Correct: 1051/1280 | Difference: 0.8576567119809041
Epoch: 03 | Batch: 1200 | CrossEntropy-loss: 0.40697 | Correct: 1076/1280 | Difference: 0.8604419622069035
Epoch: 03 | Batch: 1300 | CrossEntropy-loss: 0.39368 | Correct: 1079/1280 | Difference: 0.8631783192407088
Epoch: 03 | Batch: 1400 | CrossEntropy-loss: 0.39293 | Correct: 1080/1280 | Difference: 0.8665760236989014
Epoch: 03 | Batch: 1500 | CrossEntropy-loss: 0.38339 | Correct: 1091/1280 | Difference: 0.8687037355248426

Epoch: 03 | Testing Accuracy: 422555/504607 (83.739%) | Historical Best: 83.739% 

Epoch: 04 | Batch: 000 | CrossEntropy-loss: 0.41031 | Correct: 1053/1280 | Difference: 0.8705830521900789
Epoch: 04 | Batch: 100 | CrossEntropy-loss: 0.38399 | Correct: 1089/1280 | Difference: 0.8738316422508698
Epoch: 04 | Batch: 200 | CrossEntropy-loss: 0.40212 | Correct: 1066/1280 | Difference: 0.8765586821602807
Epoch: 04 | Batch: 300 | CrossEntropy-loss: 0.39712 | Correct: 1084/1280 | Difference: 0.8794018421622624
Epoch: 04 | Batch: 400 | CrossEntropy-loss: 0.39339 | Correct: 1062/1280 | Difference: 0.8815211619246642
Epoch: 04 | Batch: 500 | CrossEntropy-loss: 0.40018 | Correct: 1067/1280 | Difference: 0.8837007589060606
Epoch: 04 | Batch: 600 | CrossEntropy-loss: 0.39468 | Correct: 1082/1280 | Difference: 0.8853165110876171
Epoch: 04 | Batch: 700 | CrossEntropy-loss: 0.40579 | Correct: 1075/1280 | Difference: 0.8851439195465864
Epoch: 04 | Batch: 800 | CrossEntropy-loss: 0.37313 | Correct: 1082/1280 | Difference: 0.88606218025182
Epoch: 04 | Batch: 900 | CrossEntropy-loss: 0.38520 | Correct: 1090/1280 | Difference: 0.8871948603351656
Epoch: 04 | Batch: 1000 | CrossEntropy-loss: 0.35440 | Correct: 1096/1280 | Difference: 0.8876027709292423
Epoch: 04 | Batch: 1100 | CrossEntropy-loss: 0.38262 | Correct: 1082/1280 | Difference: 0.8878478619332967
Epoch: 04 | Batch: 1200 | CrossEntropy-loss: 0.34421 | Correct: 1118/1280 | Difference: 0.8880331576375645
Epoch: 04 | Batch: 1300 | CrossEntropy-loss: 0.36926 | Correct: 1093/1280 | Difference: 0.8885200459957934
Epoch: 04 | Batch: 1400 | CrossEntropy-loss: 0.35424 | Correct: 1106/1280 | Difference: 0.8879575888660854
Epoch: 04 | Batch: 1500 | CrossEntropy-loss: 0.39879 | Correct: 1084/1280 | Difference: 0.8881871903692323

Epoch: 04 | Testing Accuracy: 430308/504607 (85.276%) | Historical Best: 85.276% 

Epoch: 05 | Batch: 000 | CrossEntropy-loss: 0.38843 | Correct: 1067/1280 | Difference: 0.8886130011625316
Epoch: 05 | Batch: 100 | CrossEntropy-loss: 0.40330 | Correct: 1069/1280 | Difference: 0.888184421672095
Epoch: 05 | Batch: 200 | CrossEntropy-loss: 0.37271 | Correct: 1089/1280 | Difference: 0.8889734784649308
Epoch: 05 | Batch: 300 | CrossEntropy-loss: 0.36824 | Correct: 1096/1280 | Difference: 0.8890127362463006
Epoch: 05 | Batch: 400 | CrossEntropy-loss: 0.37923 | Correct: 1085/1280 | Difference: 0.8886651741927744
Epoch: 05 | Batch: 500 | CrossEntropy-loss: 0.37471 | Correct: 1081/1280 | Difference: 0.8889833769774997
Epoch: 05 | Batch: 600 | CrossEntropy-loss: 0.38973 | Correct: 1072/1280 | Difference: 0.8905850143018639
Epoch: 05 | Batch: 700 | CrossEntropy-loss: 0.32969 | Correct: 1118/1280 | Difference: 0.8899374324132744
Epoch: 05 | Batch: 800 | CrossEntropy-loss: 0.34700 | Correct: 1105/1280 | Difference: 0.8892884488284979
Epoch: 05 | Batch: 900 | CrossEntropy-loss: 0.36112 | Correct: 1105/1280 | Difference: 0.8883047860827796
Epoch: 05 | Batch: 1000 | CrossEntropy-loss: 0.34919 | Correct: 1096/1280 | Difference: 0.8874402765458772
Epoch: 05 | Batch: 1100 | CrossEntropy-loss: 0.33854 | Correct: 1106/1280 | Difference: 0.8866936989481046
Epoch: 05 | Batch: 1200 | CrossEntropy-loss: 0.36189 | Correct: 1089/1280 | Difference: 0.8856504252157917
Epoch: 05 | Batch: 1300 | CrossEntropy-loss: 0.38956 | Correct: 1070/1280 | Difference: 0.8841971690621697
Epoch: 05 | Batch: 1400 | CrossEntropy-loss: 0.35971 | Correct: 1079/1280 | Difference: 0.8830402535162737
Epoch: 05 | Batch: 1500 | CrossEntropy-loss: 0.34744 | Correct: 1110/1280 | Difference: 0.8814991011045851

Epoch: 05 | Testing Accuracy: 432706/504607 (85.751%) | Historical Best: 85.751% 

Epoch: 06 | Batch: 000 | CrossEntropy-loss: 0.34670 | Correct: 1095/1280 | Difference: 0.8801170516757705
Epoch: 06 | Batch: 100 | CrossEntropy-loss: 0.35314 | Correct: 1089/1280 | Difference: 0.8788608979338836
Epoch: 06 | Batch: 200 | CrossEntropy-loss: 0.35065 | Correct: 1108/1280 | Difference: 0.8776713771685477
Epoch: 06 | Batch: 300 | CrossEntropy-loss: 0.37720 | Correct: 1079/1280 | Difference: 0.8775805378468907
Epoch: 06 | Batch: 400 | CrossEntropy-loss: 0.34358 | Correct: 1100/1280 | Difference: 0.8773489181027881
Epoch: 06 | Batch: 500 | CrossEntropy-loss: 0.32252 | Correct: 1110/1280 | Difference: 0.8766070066321413
Epoch: 06 | Batch: 600 | CrossEntropy-loss: 0.36041 | Correct: 1108/1280 | Difference: 0.876426140972235
Epoch: 06 | Batch: 700 | CrossEntropy-loss: 0.35091 | Correct: 1091/1280 | Difference: 0.8759938503157767
Epoch: 06 | Batch: 800 | CrossEntropy-loss: 0.37060 | Correct: 1078/1280 | Difference: 0.8760934180480876
Epoch: 06 | Batch: 900 | CrossEntropy-loss: 0.33822 | Correct: 1096/1280 | Difference: 0.8764201023536022
Epoch: 06 | Batch: 1000 | CrossEntropy-loss: 0.37694 | Correct: 1095/1280 | Difference: 0.8767959536592412
Epoch: 06 | Batch: 1100 | CrossEntropy-loss: 0.33522 | Correct: 1104/1280 | Difference: 0.8766691716097142
Epoch: 06 | Batch: 1200 | CrossEntropy-loss: 0.34932 | Correct: 1084/1280 | Difference: 0.8764382387137151
Epoch: 06 | Batch: 1300 | CrossEntropy-loss: 0.36069 | Correct: 1090/1280 | Difference: 0.8765981691031047
Epoch: 06 | Batch: 1400 | CrossEntropy-loss: 0.32694 | Correct: 1107/1280 | Difference: 0.8766227794589241
Epoch: 06 | Batch: 1500 | CrossEntropy-loss: 0.34908 | Correct: 1085/1280 | Difference: 0.8764614051635953

Epoch: 06 | Testing Accuracy: 434989/504607 (86.204%) | Historical Best: 86.204% 

Epoch: 07 | Batch: 000 | CrossEntropy-loss: 0.33598 | Correct: 1112/1280 | Difference: 0.8765973725468521
Epoch: 07 | Batch: 100 | CrossEntropy-loss: 0.34944 | Correct: 1086/1280 | Difference: 0.8760804846105166
Epoch: 07 | Batch: 200 | CrossEntropy-loss: 0.35968 | Correct: 1089/1280 | Difference: 0.8761838446155846
Epoch: 07 | Batch: 300 | CrossEntropy-loss: 0.32541 | Correct: 1113/1280 | Difference: 0.8757927726853554
Epoch: 07 | Batch: 400 | CrossEntropy-loss: 0.31217 | Correct: 1107/1280 | Difference: 0.8754778747945836
Epoch: 07 | Batch: 500 | CrossEntropy-loss: 0.35301 | Correct: 1083/1280 | Difference: 0.8748176694295151
Epoch: 07 | Batch: 600 | CrossEntropy-loss: 0.33802 | Correct: 1104/1280 | Difference: 0.8744717626886215
Epoch: 07 | Batch: 700 | CrossEntropy-loss: 0.30657 | Correct: 1127/1280 | Difference: 0.874424131004817
Epoch: 07 | Batch: 800 | CrossEntropy-loss: 0.33164 | Correct: 1096/1280 | Difference: 0.8735949666825954
Epoch: 07 | Batch: 900 | CrossEntropy-loss: 0.32884 | Correct: 1121/1280 | Difference: 0.8735835933944358
Epoch: 07 | Batch: 1000 | CrossEntropy-loss: 0.33618 | Correct: 1103/1280 | Difference: 0.8737913376031828
Epoch: 07 | Batch: 1100 | CrossEntropy-loss: 0.33666 | Correct: 1101/1280 | Difference: 0.8737091016099007
Epoch: 07 | Batch: 1200 | CrossEntropy-loss: 0.30114 | Correct: 1133/1280 | Difference: 0.873471962012711
Epoch: 07 | Batch: 1300 | CrossEntropy-loss: 0.35966 | Correct: 1088/1280 | Difference: 0.8734893886559763
Epoch: 07 | Batch: 1400 | CrossEntropy-loss: 0.32002 | Correct: 1103/1280 | Difference: 0.87383922299881
Epoch: 07 | Batch: 1500 | CrossEntropy-loss: 0.34016 | Correct: 1092/1280 | Difference: 0.8736150579573033

Epoch: 07 | Testing Accuracy: 437611/504607 (86.723%) | Historical Best: 86.723% 

Epoch: 08 | Batch: 000 | CrossEntropy-loss: 0.36173 | Correct: 1092/1280 | Difference: 0.8736950781321899
Epoch: 08 | Batch: 100 | CrossEntropy-loss: 0.31813 | Correct: 1116/1280 | Difference: 0.873646323929605
Epoch: 08 | Batch: 200 | CrossEntropy-loss: 0.33161 | Correct: 1108/1280 | Difference: 0.8732201539936418
Epoch: 08 | Batch: 300 | CrossEntropy-loss: 0.33852 | Correct: 1107/1280 | Difference: 0.8729041969034124
Epoch: 08 | Batch: 400 | CrossEntropy-loss: 0.29453 | Correct: 1124/1280 | Difference: 0.8728707219583322
Epoch: 08 | Batch: 500 | CrossEntropy-loss: 0.32611 | Correct: 1098/1280 | Difference: 0.8727583203885707
Epoch: 08 | Batch: 600 | CrossEntropy-loss: 0.30042 | Correct: 1126/1280 | Difference: 0.8731251877393149
Epoch: 08 | Batch: 700 | CrossEntropy-loss: 0.31280 | Correct: 1126/1280 | Difference: 0.8730879637687691
Epoch: 08 | Batch: 800 | CrossEntropy-loss: 0.34976 | Correct: 1089/1280 | Difference: 0.8731738740468337
Epoch: 08 | Batch: 900 | CrossEntropy-loss: 0.32867 | Correct: 1108/1280 | Difference: 0.8730728541894124
Epoch: 08 | Batch: 1000 | CrossEntropy-loss: 0.31362 | Correct: 1121/1280 | Difference: 0.8726286774455088
Epoch: 08 | Batch: 1100 | CrossEntropy-loss: 0.33685 | Correct: 1093/1280 | Difference: 0.8729876919748103
Epoch: 08 | Batch: 1200 | CrossEntropy-loss: 0.32084 | Correct: 1104/1280 | Difference: 0.8728196822498316
Epoch: 08 | Batch: 1300 | CrossEntropy-loss: 0.30852 | Correct: 1121/1280 | Difference: 0.872837184624027
Epoch: 08 | Batch: 1400 | CrossEntropy-loss: 0.31632 | Correct: 1114/1280 | Difference: 0.8725921266976716
Epoch: 08 | Batch: 1500 | CrossEntropy-loss: 0.33056 | Correct: 1097/1280 | Difference: 0.8724604151299663

Epoch: 08 | Testing Accuracy: 440386/504607 (87.273%) | Historical Best: 87.273% 

Epoch: 09 | Batch: 000 | CrossEntropy-loss: 0.33019 | Correct: 1091/1280 | Difference: 0.872713829240043
Epoch: 09 | Batch: 100 | CrossEntropy-loss: 0.30027 | Correct: 1133/1280 | Difference: 0.8725309848509049
Epoch: 09 | Batch: 200 | CrossEntropy-loss: 0.32082 | Correct: 1099/1280 | Difference: 0.8723109578963661
Epoch: 09 | Batch: 300 | CrossEntropy-loss: 0.28661 | Correct: 1124/1280 | Difference: 0.8715525036476964
Epoch: 09 | Batch: 400 | CrossEntropy-loss: 0.31712 | Correct: 1108/1280 | Difference: 0.8715354000860531
Epoch: 09 | Batch: 500 | CrossEntropy-loss: 0.32082 | Correct: 1105/1280 | Difference: 0.8714177642983819
Epoch: 09 | Batch: 600 | CrossEntropy-loss: 0.32578 | Correct: 1120/1280 | Difference: 0.8711525987163963
Epoch: 09 | Batch: 700 | CrossEntropy-loss: 0.29565 | Correct: 1131/1280 | Difference: 0.8712656864177353
Epoch: 09 | Batch: 800 | CrossEntropy-loss: 0.32135 | Correct: 1098/1280 | Difference: 0.8706070398341363
Epoch: 09 | Batch: 900 | CrossEntropy-loss: 0.29149 | Correct: 1133/1280 | Difference: 0.87049249475107
Epoch: 09 | Batch: 1000 | CrossEntropy-loss: 0.31682 | Correct: 1122/1280 | Difference: 0.8704844900598088
Epoch: 09 | Batch: 1100 | CrossEntropy-loss: 0.32405 | Correct: 1108/1280 | Difference: 0.8706842758106638
Epoch: 09 | Batch: 1200 | CrossEntropy-loss: 0.29984 | Correct: 1128/1280 | Difference: 0.8707948120745713
Epoch: 09 | Batch: 1300 | CrossEntropy-loss: 0.27784 | Correct: 1141/1280 | Difference: 0.8706017563325743
Epoch: 09 | Batch: 1400 | CrossEntropy-loss: 0.27964 | Correct: 1139/1280 | Difference: 0.8703234263177672
Epoch: 09 | Batch: 1500 | CrossEntropy-loss: 0.29957 | Correct: 1122/1280 | Difference: 0.8707358672151821

Epoch: 09 | Testing Accuracy: 443609/504607 (87.912%) | Historical Best: 87.912% 

Epoch: 10 | Batch: 000 | CrossEntropy-loss: 0.29597 | Correct: 1125/1280 | Difference: 0.870838345018663
Epoch: 10 | Batch: 100 | CrossEntropy-loss: 0.30365 | Correct: 1124/1280 | Difference: 0.8707156787863162
Epoch: 10 | Batch: 200 | CrossEntropy-loss: 0.30919 | Correct: 1117/1280 | Difference: 0.8710031210764234
Epoch: 10 | Batch: 300 | CrossEntropy-loss: 0.30248 | Correct: 1138/1280 | Difference: 0.8711505557142076
Epoch: 10 | Batch: 400 | CrossEntropy-loss: 0.30765 | Correct: 1124/1280 | Difference: 0.8712533967217572
Epoch: 10 | Batch: 500 | CrossEntropy-loss: 0.29050 | Correct: 1141/1280 | Difference: 0.8715422757638541
Epoch: 10 | Batch: 600 | CrossEntropy-loss: 0.28532 | Correct: 1115/1280 | Difference: 0.8718802846047902
Epoch: 10 | Batch: 700 | CrossEntropy-loss: 0.29131 | Correct: 1125/1280 | Difference: 0.8713846017550011
Epoch: 10 | Batch: 800 | CrossEntropy-loss: 0.29501 | Correct: 1123/1280 | Difference: 0.8720823014534104
Epoch: 10 | Batch: 900 | CrossEntropy-loss: 0.31616 | Correct: 1110/1280 | Difference: 0.8721340500505336
Epoch: 10 | Batch: 1000 | CrossEntropy-loss: 0.29014 | Correct: 1118/1280 | Difference: 0.8721462390407885
Epoch: 10 | Batch: 1100 | CrossEntropy-loss: 0.27783 | Correct: 1146/1280 | Difference: 0.8724111073529571
Epoch: 10 | Batch: 1200 | CrossEntropy-loss: 0.26863 | Correct: 1145/1280 | Difference: 0.8725076205667271
Epoch: 10 | Batch: 1300 | CrossEntropy-loss: 0.29535 | Correct: 1115/1280 | Difference: 0.8722556807437877
Epoch: 10 | Batch: 1400 | CrossEntropy-loss: 0.30117 | Correct: 1127/1280 | Difference: 0.8724208219494709
Epoch: 10 | Batch: 1500 | CrossEntropy-loss: 0.30365 | Correct: 1113/1280 | Difference: 0.8724502879769351

Epoch: 10 | Testing Accuracy: 445374/504607 (88.262%) | Historical Best: 88.262% 

Epoch: 11 | Batch: 000 | CrossEntropy-loss: 0.30892 | Correct: 1114/1280 | Difference: 0.8724195783589718
Epoch: 11 | Batch: 100 | CrossEntropy-loss: 0.29515 | Correct: 1119/1280 | Difference: 0.8718858314284019
Epoch: 11 | Batch: 200 | CrossEntropy-loss: 0.28492 | Correct: 1134/1280 | Difference: 0.8716452116834051
Epoch: 11 | Batch: 300 | CrossEntropy-loss: 0.31216 | Correct: 1128/1280 | Difference: 0.8714853652493734
Epoch: 11 | Batch: 400 | CrossEntropy-loss: 0.29784 | Correct: 1123/1280 | Difference: 0.8708920304893999
Epoch: 11 | Batch: 500 | CrossEntropy-loss: 0.29880 | Correct: 1121/1280 | Difference: 0.8708921509057127
Epoch: 11 | Batch: 600 | CrossEntropy-loss: 0.28139 | Correct: 1121/1280 | Difference: 0.8705549555014032
Epoch: 11 | Batch: 700 | CrossEntropy-loss: 0.27904 | Correct: 1141/1280 | Difference: 0.8702892661549583
Epoch: 11 | Batch: 800 | CrossEntropy-loss: 0.30165 | Correct: 1104/1280 | Difference: 0.8703441690883043
Epoch: 11 | Batch: 900 | CrossEntropy-loss: 0.27091 | Correct: 1135/1280 | Difference: 0.8700479937419322
Epoch: 11 | Batch: 1000 | CrossEntropy-loss: 0.30351 | Correct: 1128/1280 | Difference: 0.86940766329631
Epoch: 11 | Batch: 1100 | CrossEntropy-loss: 0.28361 | Correct: 1135/1280 | Difference: 0.8694689219258821
Epoch: 11 | Batch: 1200 | CrossEntropy-loss: 0.27621 | Correct: 1145/1280 | Difference: 0.8691534120726648
Epoch: 11 | Batch: 1300 | CrossEntropy-loss: 0.30174 | Correct: 1120/1280 | Difference: 0.8693413291531543
Epoch: 11 | Batch: 1400 | CrossEntropy-loss: 0.26284 | Correct: 1145/1280 | Difference: 0.8689193664900408
Epoch: 11 | Batch: 1500 | CrossEntropy-loss: 0.29741 | Correct: 1129/1280 | Difference: 0.8692483404077369

Epoch: 11 | Testing Accuracy: 447253/504607 (88.634%) | Historical Best: 88.634% 

Epoch: 12 | Batch: 000 | CrossEntropy-loss: 0.27518 | Correct: 1142/1280 | Difference: 0.8686425857802362
Epoch: 12 | Batch: 100 | CrossEntropy-loss: 0.26204 | Correct: 1138/1280 | Difference: 0.8684801411270082
Epoch: 12 | Batch: 200 | CrossEntropy-loss: 0.27607 | Correct: 1138/1280 | Difference: 0.8679698820553405
Epoch: 12 | Batch: 300 | CrossEntropy-loss: 0.29863 | Correct: 1123/1280 | Difference: 0.8677802127988862
Epoch: 12 | Batch: 400 | CrossEntropy-loss: 0.27706 | Correct: 1139/1280 | Difference: 0.8674946083831653
Epoch: 12 | Batch: 500 | CrossEntropy-loss: 0.28058 | Correct: 1131/1280 | Difference: 0.8678336019067594
Epoch: 12 | Batch: 600 | CrossEntropy-loss: 0.30044 | Correct: 1119/1280 | Difference: 0.8672916461509743
Epoch: 12 | Batch: 700 | CrossEntropy-loss: 0.28074 | Correct: 1125/1280 | Difference: 0.8673413188170868
Epoch: 12 | Batch: 800 | CrossEntropy-loss: 0.24925 | Correct: 1147/1280 | Difference: 0.8671489650115147
Epoch: 12 | Batch: 900 | CrossEntropy-loss: 0.25700 | Correct: 1148/1280 | Difference: 0.8667907611828838
Epoch: 12 | Batch: 1000 | CrossEntropy-loss: 0.27867 | Correct: 1134/1280 | Difference: 0.8665712856896814
Epoch: 12 | Batch: 1100 | CrossEntropy-loss: 0.29490 | Correct: 1115/1280 | Difference: 0.8665888991355547
Epoch: 12 | Batch: 1200 | CrossEntropy-loss: 0.27930 | Correct: 1147/1280 | Difference: 0.8662985884638638
Epoch: 12 | Batch: 1300 | CrossEntropy-loss: 0.29101 | Correct: 1124/1280 | Difference: 0.865906844660328
Epoch: 12 | Batch: 1400 | CrossEntropy-loss: 0.29133 | Correct: 1124/1280 | Difference: 0.865350623941608
Epoch: 12 | Batch: 1500 | CrossEntropy-loss: 0.27941 | Correct: 1130/1280 | Difference: 0.8651892133550432

Epoch: 12 | Testing Accuracy: 448603/504607 (88.901%) | Historical Best: 88.901% 

Epoch: 13 | Batch: 000 | CrossEntropy-loss: 0.26142 | Correct: 1145/1280 | Difference: 0.8648123639601432
Epoch: 13 | Batch: 100 | CrossEntropy-loss: 0.27177 | Correct: 1141/1280 | Difference: 0.8645645276498947
Epoch: 13 | Batch: 200 | CrossEntropy-loss: 0.27230 | Correct: 1140/1280 | Difference: 0.8639508824313116
Epoch: 13 | Batch: 300 | CrossEntropy-loss: 0.30473 | Correct: 1123/1280 | Difference: 0.8638812872142002
Epoch: 13 | Batch: 400 | CrossEntropy-loss: 0.30118 | Correct: 1128/1280 | Difference: 0.8635125308291561
Epoch: 13 | Batch: 500 | CrossEntropy-loss: 0.28351 | Correct: 1123/1280 | Difference: 0.8634599616805148
Epoch: 13 | Batch: 600 | CrossEntropy-loss: 0.28700 | Correct: 1120/1280 | Difference: 0.8633571007316777
Epoch: 13 | Batch: 700 | CrossEntropy-loss: 0.25673 | Correct: 1149/1280 | Difference: 0.8631297807330862
Epoch: 13 | Batch: 800 | CrossEntropy-loss: 0.27807 | Correct: 1134/1280 | Difference: 0.8632598299639775
Epoch: 13 | Batch: 900 | CrossEntropy-loss: 0.27566 | Correct: 1137/1280 | Difference: 0.8629882569540366
Epoch: 13 | Batch: 1000 | CrossEntropy-loss: 0.28251 | Correct: 1117/1280 | Difference: 0.8630132709870256
Epoch: 13 | Batch: 1100 | CrossEntropy-loss: 0.27172 | Correct: 1139/1280 | Difference: 0.8625592335641689
Epoch: 13 | Batch: 1200 | CrossEntropy-loss: 0.27568 | Correct: 1145/1280 | Difference: 0.8621403740001312
Epoch: 13 | Batch: 1300 | CrossEntropy-loss: 0.27690 | Correct: 1130/1280 | Difference: 0.8618270391167978
Epoch: 13 | Batch: 1400 | CrossEntropy-loss: 0.25470 | Correct: 1153/1280 | Difference: 0.8613647453567279
Epoch: 13 | Batch: 1500 | CrossEntropy-loss: 0.27951 | Correct: 1139/1280 | Difference: 0.8612118296781099

Epoch: 13 | Testing Accuracy: 449223/504607 (89.024%) | Historical Best: 89.024% 

Epoch: 14 | Batch: 000 | CrossEntropy-loss: 0.26683 | Correct: 1132/1280 | Difference: 0.8609314083425488
Epoch: 14 | Batch: 100 | CrossEntropy-loss: 0.28150 | Correct: 1144/1280 | Difference: 0.8610788507335966
Epoch: 14 | Batch: 200 | CrossEntropy-loss: 0.28488 | Correct: 1133/1280 | Difference: 0.8612225446231929
Epoch: 14 | Batch: 300 | CrossEntropy-loss: 0.28220 | Correct: 1129/1280 | Difference: 0.8606728760380624
Epoch: 14 | Batch: 400 | CrossEntropy-loss: 0.27969 | Correct: 1137/1280 | Difference: 0.8610220492796428
Epoch: 14 | Batch: 500 | CrossEntropy-loss: 0.26719 | Correct: 1154/1280 | Difference: 0.8607184348031812
Epoch: 14 | Batch: 600 | CrossEntropy-loss: 0.25643 | Correct: 1148/1280 | Difference: 0.860344134679448
Epoch: 14 | Batch: 700 | CrossEntropy-loss: 0.27775 | Correct: 1128/1280 | Difference: 0.8599314833775026
Epoch: 14 | Batch: 800 | CrossEntropy-loss: 0.28208 | Correct: 1124/1280 | Difference: 0.8597292553602968
Epoch: 14 | Batch: 900 | CrossEntropy-loss: 0.28476 | Correct: 1138/1280 | Difference: 0.8597530810872364
Epoch: 14 | Batch: 1000 | CrossEntropy-loss: 0.25996 | Correct: 1134/1280 | Difference: 0.8595368735882343
Epoch: 14 | Batch: 1100 | CrossEntropy-loss: 0.25759 | Correct: 1137/1280 | Difference: 0.8594006525032953
Epoch: 14 | Batch: 1200 | CrossEntropy-loss: 0.27199 | Correct: 1131/1280 | Difference: 0.8588965196737208
Epoch: 14 | Batch: 1300 | CrossEntropy-loss: 0.28162 | Correct: 1124/1280 | Difference: 0.8588179658835694
Epoch: 14 | Batch: 1400 | CrossEntropy-loss: 0.25601 | Correct: 1154/1280 | Difference: 0.8585062151611588
Epoch: 14 | Batch: 1500 | CrossEntropy-loss: 0.28652 | Correct: 1133/1280 | Difference: 0.8581261661736935

Epoch: 14 | Testing Accuracy: 449117/504607 (89.003%) | Historical Best: 89.024% 

Epoch: 15 | Batch: 000 | CrossEntropy-loss: 0.28396 | Correct: 1127/1280 | Difference: 0.8574785396099521
Epoch: 15 | Batch: 100 | CrossEntropy-loss: 0.27904 | Correct: 1134/1280 | Difference: 0.8574078967761158
Epoch: 15 | Batch: 200 | CrossEntropy-loss: 0.28976 | Correct: 1124/1280 | Difference: 0.8574372569413758
Epoch: 15 | Batch: 300 | CrossEntropy-loss: 0.24335 | Correct: 1151/1280 | Difference: 0.8571897884064303
Epoch: 15 | Batch: 400 | CrossEntropy-loss: 0.29372 | Correct: 1127/1280 | Difference: 0.8568992202000763
Epoch: 15 | Batch: 500 | CrossEntropy-loss: 0.29323 | Correct: 1128/1280 | Difference: 0.8569078585523662
Epoch: 15 | Batch: 600 | CrossEntropy-loss: 0.28702 | Correct: 1142/1280 | Difference: 0.8563649358618587
Epoch: 15 | Batch: 700 | CrossEntropy-loss: 0.25092 | Correct: 1136/1280 | Difference: 0.8561670128997945
Epoch: 15 | Batch: 800 | CrossEntropy-loss: 0.28410 | Correct: 1128/1280 | Difference: 0.8559054288926927
Epoch: 15 | Batch: 900 | CrossEntropy-loss: 0.26256 | Correct: 1150/1280 | Difference: 0.855492655291226
Epoch: 15 | Batch: 1000 | CrossEntropy-loss: 0.26897 | Correct: 1134/1280 | Difference: 0.8555866687240161
Epoch: 15 | Batch: 1100 | CrossEntropy-loss: 0.25798 | Correct: 1146/1280 | Difference: 0.8555096307110509
Epoch: 15 | Batch: 1200 | CrossEntropy-loss: 0.28290 | Correct: 1120/1280 | Difference: 0.8558479089928462
Epoch: 15 | Batch: 1300 | CrossEntropy-loss: 0.26970 | Correct: 1126/1280 | Difference: 0.8555802813081613
Epoch: 15 | Batch: 1400 | CrossEntropy-loss: 0.25011 | Correct: 1158/1280 | Difference: 0.8555422193543657
Epoch: 15 | Batch: 1500 | CrossEntropy-loss: 0.26135 | Correct: 1156/1280 | Difference: 0.855508109403984

Epoch: 15 | Testing Accuracy: 450670/504607 (89.311%) | Historical Best: 89.311% 

Epoch: 16 | Batch: 000 | CrossEntropy-loss: 0.26299 | Correct: 1141/1280 | Difference: 0.8552978563032506
Epoch: 16 | Batch: 100 | CrossEntropy-loss: 0.27032 | Correct: 1143/1280 | Difference: 0.8554432536743112
Epoch: 16 | Batch: 200 | CrossEntropy-loss: 0.27371 | Correct: 1133/1280 | Difference: 0.8552504875583545
Epoch: 16 | Batch: 300 | CrossEntropy-loss: 0.27270 | Correct: 1129/1280 | Difference: 0.8552184844570618
Epoch: 16 | Batch: 400 | CrossEntropy-loss: 0.28068 | Correct: 1128/1280 | Difference: 0.8551678166438264
Epoch: 16 | Batch: 500 | CrossEntropy-loss: 0.26755 | Correct: 1134/1280 | Difference: 0.8551792195428444
Epoch: 16 | Batch: 600 | CrossEntropy-loss: 0.28922 | Correct: 1126/1280 | Difference: 0.8556063936013902
Epoch: 16 | Batch: 700 | CrossEntropy-loss: 0.25728 | Correct: 1157/1280 | Difference: 0.8553212112771408
Epoch: 16 | Batch: 800 | CrossEntropy-loss: 0.27702 | Correct: 1129/1280 | Difference: 0.8553637535820934
Epoch: 16 | Batch: 900 | CrossEntropy-loss: 0.24929 | Correct: 1153/1280 | Difference: 0.8551093481637105
Epoch: 16 | Batch: 1000 | CrossEntropy-loss: 0.29020 | Correct: 1134/1280 | Difference: 0.8549286429918962
Epoch: 16 | Batch: 1100 | CrossEntropy-loss: 0.26590 | Correct: 1148/1280 | Difference: 0.8548632411223903
Epoch: 16 | Batch: 1200 | CrossEntropy-loss: 0.28482 | Correct: 1119/1280 | Difference: 0.85516359777134
Epoch: 16 | Batch: 1300 | CrossEntropy-loss: 0.24664 | Correct: 1148/1280 | Difference: 0.855267128510098
Epoch: 16 | Batch: 1400 | CrossEntropy-loss: 0.24594 | Correct: 1157/1280 | Difference: 0.8551910097829886
Epoch: 16 | Batch: 1500 | CrossEntropy-loss: 0.26955 | Correct: 1131/1280 | Difference: 0.8553313911041135

Epoch: 16 | Testing Accuracy: 450393/504607 (89.256%) | Historical Best: 89.311% 

Epoch: 17 | Batch: 000 | CrossEntropy-loss: 0.26329 | Correct: 1143/1280 | Difference: 0.8554193442509197
Epoch: 17 | Batch: 100 | CrossEntropy-loss: 0.24980 | Correct: 1158/1280 | Difference: 0.85536611867524
Traceback (most recent call last):
  File "sdt_train.py", line 151, in <module>
    train_tree(tree)
  File "sdt_train.py", line 73, in train_tree
    prediction, output, penalty, weights = tree.forward(data)
  File "/home/zihan/Soft-Decision-Tree/SDT.py", line 62, in forward
    _mu, _penalty, _alpha = self._forward(data)
  File "/home/zihan/Soft-Decision-Tree/SDT.py", line 114, in _forward
    return mu, _penalty, torch.mean(torch.stack(half_alpha_list)).detach().cpu().numpy()   # mu contains the path probability for each leaf       
RuntimeError: expected a non-empty list of Tensors
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/zihan/anaconda3/envs/exp/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
{'input_dim': 8, 'output_dim': 4, 'depth': 5, 'lamda': -0.001, 'lr': 0.001, 'weight_decay': 0.0, 'batch_size': 1280, 'epochs': 40, 'cuda': True, 'log_interval': 100, 'exp_scheduler_gamma': 1.0, 'beta': True, 'greatest_path_probability': True, 'model_path': './model/trees/sdt_-0.001_id2'}
Epoch: 01 | Batch: 000 | CrossEntropy-loss: 1.29440 | Correct: 480/1280 | Difference: 0.9399499612210934
Epoch: 01 | Batch: 100 | CrossEntropy-loss: 1.19372 | Correct: 775/1280 | Difference: 0.9445653863284731
Epoch: 01 | Batch: 200 | CrossEntropy-loss: 1.08531 | Correct: 914/1280 | Difference: 0.9417282042334556
Epoch: 01 | Batch: 300 | CrossEntropy-loss: 0.99301 | Correct: 951/1280 | Difference: 0.9337458590068886
Epoch: 01 | Batch: 400 | CrossEntropy-loss: 0.90620 | Correct: 942/1280 | Difference: 0.9089060467319301
Epoch: 01 | Batch: 500 | CrossEntropy-loss: 0.82257 | Correct: 964/1280 | Difference: 0.8973265790813122
Epoch: 01 | Batch: 600 | CrossEntropy-loss: 0.79573 | Correct: 930/1280 | Difference: 0.8754455024453436
Epoch: 01 | Batch: 700 | CrossEntropy-loss: 0.75931 | Correct: 933/1280 | Difference: 0.8463896418841491
Epoch: 01 | Batch: 800 | CrossEntropy-loss: 0.71479 | Correct: 957/1280 | Difference: 0.8215624982842562
Epoch: 01 | Batch: 900 | CrossEntropy-loss: 0.70915 | Correct: 949/1280 | Difference: 0.8029699219473451
Epoch: 01 | Batch: 1000 | CrossEntropy-loss: 0.68951 | Correct: 946/1280 | Difference: 0.7859400207752205
Epoch: 01 | Batch: 1100 | CrossEntropy-loss: 0.62098 | Correct: 979/1280 | Difference: 0.7684188165787862
Epoch: 01 | Batch: 1200 | CrossEntropy-loss: 0.63452 | Correct: 992/1280 | Difference: 0.7531012012080024
Epoch: 01 | Batch: 1300 | CrossEntropy-loss: 0.59613 | Correct: 1002/1280 | Difference: 0.7423523079462865
Epoch: 01 | Batch: 1400 | CrossEntropy-loss: 0.59435 | Correct: 1020/1280 | Difference: 0.7354875071393393
Epoch: 01 | Batch: 1500 | CrossEntropy-loss: 0.59573 | Correct: 1032/1280 | Difference: 0.7299777805377978

Epoch: 01 | Testing Accuracy: 402863/504607 (79.837%) | Historical Best: 79.837% 

Epoch: 02 | Batch: 000 | CrossEntropy-loss: 0.59590 | Correct: 1015/1280 | Difference: 0.7274592530165964
Epoch: 02 | Batch: 100 | CrossEntropy-loss: 0.55671 | Correct: 1038/1280 | Difference: 0.7246770267184243
Epoch: 02 | Batch: 200 | CrossEntropy-loss: 0.58049 | Correct: 1017/1280 | Difference: 0.7242834950364608
Epoch: 02 | Batch: 300 | CrossEntropy-loss: 0.56484 | Correct: 1026/1280 | Difference: 0.72521173205019
Epoch: 02 | Batch: 400 | CrossEntropy-loss: 0.55638 | Correct: 1037/1280 | Difference: 0.7266918194526438
Epoch: 02 | Batch: 500 | CrossEntropy-loss: 0.53636 | Correct: 1029/1280 | Difference: 0.7266988202407303
Epoch: 02 | Batch: 600 | CrossEntropy-loss: 0.52360 | Correct: 1039/1280 | Difference: 0.7276682110029941
Epoch: 02 | Batch: 700 | CrossEntropy-loss: 0.54733 | Correct: 1012/1280 | Difference: 0.7285220115189718
Epoch: 02 | Batch: 800 | CrossEntropy-loss: 0.53631 | Correct: 1017/1280 | Difference: 0.72888473944118
Epoch: 02 | Batch: 900 | CrossEntropy-loss: 0.50539 | Correct: 1024/1280 | Difference: 0.7303775494532988
Epoch: 02 | Batch: 1000 | CrossEntropy-loss: 0.48784 | Correct: 1047/1280 | Difference: 0.7325413899926303
Epoch: 02 | Batch: 1100 | CrossEntropy-loss: 0.50992 | Correct: 1034/1280 | Difference: 0.7357476829118381
Epoch: 02 | Batch: 1200 | CrossEntropy-loss: 0.49554 | Correct: 1028/1280 | Difference: 0.737862754614242
Epoch: 02 | Batch: 1300 | CrossEntropy-loss: 0.49458 | Correct: 1043/1280 | Difference: 0.7394862113666032
Epoch: 02 | Batch: 1400 | CrossEntropy-loss: 0.46695 | Correct: 1031/1280 | Difference: 0.7415826974289595
Epoch: 02 | Batch: 1500 | CrossEntropy-loss: 0.46698 | Correct: 1038/1280 | Difference: 0.7435466710396725

Epoch: 02 | Testing Accuracy: 412398/504607 (81.727%) | Historical Best: 81.727% 

Epoch: 03 | Batch: 000 | CrossEntropy-loss: 0.44301 | Correct: 1069/1280 | Difference: 0.7457839427592874
Epoch: 03 | Batch: 100 | CrossEntropy-loss: 0.46048 | Correct: 1063/1280 | Difference: 0.749357974660726
Epoch: 03 | Batch: 200 | CrossEntropy-loss: 0.46118 | Correct: 1068/1280 | Difference: 0.7531108277547104
Epoch: 03 | Batch: 300 | CrossEntropy-loss: 0.47358 | Correct: 1046/1280 | Difference: 0.7580146093906239
Epoch: 03 | Batch: 400 | CrossEntropy-loss: 0.50122 | Correct: 1037/1280 | Difference: 0.76172511483216
Epoch: 03 | Batch: 500 | CrossEntropy-loss: 0.47154 | Correct: 1034/1280 | Difference: 0.7644024106440422
Epoch: 03 | Batch: 600 | CrossEntropy-loss: 0.43598 | Correct: 1062/1280 | Difference: 0.7681984832959945
Epoch: 03 | Batch: 700 | CrossEntropy-loss: 0.44184 | Correct: 1072/1280 | Difference: 0.7729321765083055
Epoch: 03 | Batch: 800 | CrossEntropy-loss: 0.43286 | Correct: 1059/1280 | Difference: 0.7786309990435989
Epoch: 03 | Batch: 900 | CrossEntropy-loss: 0.44405 | Correct: 1047/1280 | Difference: 0.784775480750594
Epoch: 03 | Batch: 1000 | CrossEntropy-loss: 0.42408 | Correct: 1077/1280 | Difference: 0.7924241907950661
Epoch: 03 | Batch: 1100 | CrossEntropy-loss: 0.45931 | Correct: 1046/1280 | Difference: 0.8001568705036656
Epoch: 03 | Batch: 1200 | CrossEntropy-loss: 0.45249 | Correct: 1045/1280 | Difference: 0.8073705191624007
Epoch: 03 | Batch: 1300 | CrossEntropy-loss: 0.40867 | Correct: 1062/1280 | Difference: 0.8142790655863681
Epoch: 03 | Batch: 1400 | CrossEntropy-loss: 0.41895 | Correct: 1070/1280 | Difference: 0.8209415219224666
Epoch: 03 | Batch: 1500 | CrossEntropy-loss: 0.39198 | Correct: 1070/1280 | Difference: 0.8260388855216773

Epoch: 03 | Testing Accuracy: 419567/504607 (83.147%) | Historical Best: 83.147% 

Epoch: 04 | Batch: 000 | CrossEntropy-loss: 0.40723 | Correct: 1069/1280 | Difference: 0.8308735582906583
Epoch: 04 | Batch: 100 | CrossEntropy-loss: 0.42143 | Correct: 1062/1280 | Difference: 0.8374658077703455
Epoch: 04 | Batch: 200 | CrossEntropy-loss: 0.42165 | Correct: 1069/1280 | Difference: 0.8425528037015523
Epoch: 04 | Batch: 300 | CrossEntropy-loss: 0.38900 | Correct: 1106/1280 | Difference: 0.8462345050256473
Epoch: 04 | Batch: 400 | CrossEntropy-loss: 0.44512 | Correct: 1073/1280 | Difference: 0.8497359084295439
Epoch: 04 | Batch: 500 | CrossEntropy-loss: 0.42876 | Correct: 1056/1280 | Difference: 0.8520574177877976
Epoch: 04 | Batch: 600 | CrossEntropy-loss: 0.39994 | Correct: 1074/1280 | Difference: 0.8565868098416717
Epoch: 04 | Batch: 700 | CrossEntropy-loss: 0.42838 | Correct: 1056/1280 | Difference: 0.8626631332693544
Epoch: 04 | Batch: 800 | CrossEntropy-loss: 0.43534 | Correct: 1052/1280 | Difference: 0.8657593740349653
Epoch: 04 | Batch: 900 | CrossEntropy-loss: 0.41355 | Correct: 1067/1280 | Difference: 0.8689599384949777
Epoch: 04 | Batch: 1000 | CrossEntropy-loss: 0.39548 | Correct: 1080/1280 | Difference: 0.8700650520384661
Epoch: 04 | Batch: 1100 | CrossEntropy-loss: 0.41527 | Correct: 1072/1280 | Difference: 0.8749080014773333
Epoch: 04 | Batch: 1200 | CrossEntropy-loss: 0.38928 | Correct: 1073/1280 | Difference: 0.8809046806699333
Epoch: 04 | Batch: 1300 | CrossEntropy-loss: 0.38723 | Correct: 1077/1280 | Difference: 0.8855476885108803
Epoch: 04 | Batch: 1400 | CrossEntropy-loss: 0.39049 | Correct: 1085/1280 | Difference: 0.8920297749982972
Epoch: 04 | Batch: 1500 | CrossEntropy-loss: 0.39830 | Correct: 1062/1280 | Difference: 0.8969457459105233

Epoch: 04 | Testing Accuracy: 421456/504607 (83.522%) | Historical Best: 83.522% 

Epoch: 05 | Batch: 000 | CrossEntropy-loss: 0.40821 | Correct: 1075/1280 | Difference: 0.9013440549433043
Epoch: 05 | Batch: 100 | CrossEntropy-loss: 0.40989 | Correct: 1065/1280 | Difference: 0.9070658483697763
Epoch: 05 | Batch: 200 | CrossEntropy-loss: 0.41614 | Correct: 1062/1280 | Difference: 0.9122770694067144
Epoch: 05 | Batch: 300 | CrossEntropy-loss: 0.41860 | Correct: 1059/1280 | Difference: 0.9185810494006136
Epoch: 05 | Batch: 400 | CrossEntropy-loss: 0.38196 | Correct: 1062/1280 | Difference: 0.9229493851121043
Epoch: 05 | Batch: 500 | CrossEntropy-loss: 0.40563 | Correct: 1061/1280 | Difference: 0.9274657852895903
Epoch: 05 | Batch: 600 | CrossEntropy-loss: 0.38635 | Correct: 1073/1280 | Difference: 0.9316433564807529
Epoch: 05 | Batch: 700 | CrossEntropy-loss: 0.41469 | Correct: 1047/1280 | Difference: 0.9358801860480475
Epoch: 05 | Batch: 800 | CrossEntropy-loss: 0.36729 | Correct: 1081/1280 | Difference: 0.9385517489839187
Epoch: 05 | Batch: 900 | CrossEntropy-loss: 0.40714 | Correct: 1071/1280 | Difference: 0.9412965674657456
Traceback (most recent call last):
  File "sdt_train.py", line 151, in <module>
    train_tree(tree)
  File "sdt_train.py", line 73, in train_tree
    prediction, output, penalty, weights = tree.forward(data)
  File "/home/zihan/Soft-Decision-Tree/SDT.py", line 62, in forward
    _mu, _penalty, _alpha = self._forward(data)
  File "/home/zihan/Soft-Decision-Tree/SDT.py", line 114, in _forward
    return mu, _penalty, torch.mean(torch.stack(half_alpha_list)).detach().cpu().numpy()   # mu contains the path probability for each leaf       
RuntimeError: expected a non-empty list of Tensors
